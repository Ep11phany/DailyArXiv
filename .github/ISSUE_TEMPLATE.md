---
title: Latest 15 Papers - April 07, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models](http://arxiv.org/abs/2504.02821v1)** | 2025-04-03 | <details><summary>Prepr...</summary><p>Preprint. The code is available at https://github.com/ExplainableML/sae-for-vlm</p></details> |
| **[Generative Evaluation of Complex Reasoning in Large Language Models](http://arxiv.org/abs/2504.02810v1)** | 2025-04-03 |  |
| **[Measuring temporal effects of agent knowledge by date-controlled tool use](http://arxiv.org/abs/2503.04188v2)** | 2025-04-03 | <details><summary>under...</summary><p>under review, comments welcome</p></details> |
| **[MegaMath: Pushing the Limits of Open Math Corpora](http://arxiv.org/abs/2504.02807v1)** | 2025-04-03 | <details><summary>26 pa...</summary><p>26 pages, 15 figures, 22 tables</p></details> |
| **[A Survey of Large Language Models in Mental Health Disorder Detection on Social Media](http://arxiv.org/abs/2504.02800v2)** | 2025-04-04 | 13 pages, 4 figures |
| **[BIRD: A Trustworthy Bayesian Inference Framework for Large Language Models](http://arxiv.org/abs/2404.12494v3)** | 2025-04-03 |  |
| **[ADO-LLM: Analog Design Bayesian Optimization with In-Context Learning of Large Language Models](http://arxiv.org/abs/2406.18770v2)** | 2025-04-03 | 9 pages, 3 figures |
| **[A Framework for Robust Cognitive Evaluation of LLMs](http://arxiv.org/abs/2504.02789v1)** | 2025-04-03 |  |
| **[From Consumption to Collaboration: Measuring Interaction Patterns to Augment Human Cognition in Open-Ended Tasks](http://arxiv.org/abs/2504.02780v1)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted at Tools for Thought Workshop (CHI'25)</p></details> |
| **[BT-ACTION: A Test-Driven Approach for Modular Understanding of User Instruction Leveraging Behaviour Trees and LLMs](http://arxiv.org/abs/2504.02779v1)** | 2025-04-03 |  |
| **[How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?](http://arxiv.org/abs/2504.02767v1)** | 2025-04-03 | 32 pages, 17 figures |
| **[Measuring Large Language Models Capacity to Annotate Journalistic Sourcing](http://arxiv.org/abs/2501.00164v2)** | 2025-04-03 |  |
| **[Enhancing LLM Robustness to Perturbed Instructions: An Empirical Study](http://arxiv.org/abs/2504.02733v1)** | 2025-04-03 | <details><summary>Build...</summary><p>Building Trust Workshop, ICLR 2025</p></details> |
| **[Why do LLMs attend to the first token?](http://arxiv.org/abs/2504.02732v2)** | 2025-04-04 |  |
| **[Reducing Reasoning Costs: The Path of Optimization for Chain of Thought via Sparse Attention Mechanism](http://arxiv.org/abs/2411.09111v6)** | 2025-04-03 | <details><summary>The m...</summary><p>The main text is 5 pages, totaling 9 pages; 4 figures, 1 table. It have been submitted to NeurIPS 2024 Workshop MusIML and OpenReview</p></details> |

## RAG
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Retrieving Semantics from the Deep: an RAG Solution for Gesture Synthesis](http://arxiv.org/abs/2412.06786v3)** | 2025-04-04 | <details><summary>CVPR ...</summary><p>CVPR 2025. Project page: https://vcai.mpi-inf.mpg.de/projects/RAG-Gesture/</p></details> |
| **[GTR: Graph-Table-RAG for Cross-Table Question Answering](http://arxiv.org/abs/2504.01346v2)** | 2025-04-03 | 20 pages, 7 figures |
| **[Real-Time Evaluation Models for RAG: Who Detects Hallucinations Best?](http://arxiv.org/abs/2503.21157v2)** | 2025-04-02 | 11 pages, 8 figures |
| **[From Code Generation to Software Testing: AI Copilot with Context-Based RAG](http://arxiv.org/abs/2504.01866v1)** | 2025-04-02 | <details><summary>This ...</summary><p>This work has been accepted for publication in IEEE Software (DOI: 10.1109/MS.2025.3549628)</p></details> |
| **[Beyond Quacking: Deep Integration of Language Models and RAG into DuckDB](http://arxiv.org/abs/2504.01157v1)** | 2025-04-01 |  |
| **[Self-Routing RAG: Binding Selective Retrieval with Knowledge Verbalization](http://arxiv.org/abs/2504.01018v1)** | 2025-04-01 | Work in Progress |
| **[TOBUGraph: Knowledge Graph-Based Retrieval for Enhanced LLM Performance Beyond RAG](http://arxiv.org/abs/2412.05447v2)** | 2025-04-01 |  |
| **[Contradiction Detection in RAG Systems: Evaluating LLMs as Context Validators for Improved Information Consistency](http://arxiv.org/abs/2504.00180v1)** | 2025-03-31 |  |
| **[A Systematic Evaluation of LLM Strategies for Mental Health Text Analysis: Fine-tuning vs. Prompt Engineering vs. RAG](http://arxiv.org/abs/2503.24307v1)** | 2025-03-31 |  |
| **[A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](http://arxiv.org/abs/2402.07877v3)** | 2025-03-28 |  |
| **[Systematic Knowledge Injection into Large Language Models via Diverse Augmentation for Domain-Specific RAG](http://arxiv.org/abs/2502.08356v3)** | 2025-03-27 | <details><summary>22 pa...</summary><p>22 pages, 14 tables, to be published in NAACL 2025</p></details> |
| **[Does RAG Introduce Unfairness in LLMs? Evaluating Fairness in Retrieval-Augmented Generation Systems](http://arxiv.org/abs/2409.19804v2)** | 2025-03-27 | <details><summary>Publi...</summary><p>Published at COLING 2025</p></details> |
| **[Balancing Content Size in RAG-Text2SQL System](http://arxiv.org/abs/2502.15723v3)** | 2025-03-23 |  |
| **[Tuning LLMs by RAG Principles: Towards LLM-native Memory](http://arxiv.org/abs/2503.16071v1)** | 2025-03-20 |  |
| **[FutureGen: LLM-RAG Approach to Generate the Future Work of Scientific Article](http://arxiv.org/abs/2503.16561v1)** | 2025-03-20 | 19 pages, 5 figures |

