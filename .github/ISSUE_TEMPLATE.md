---
title: Latest 15 Papers - May 27, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[KnowTrace: Bootstrapping Iterative Retrieval-Augmented Generation with Structured Knowledge Tracing](http://arxiv.org/abs/2505.20245v1)** | 2025-05-26 | Accepted by KDD 2025 |
| **[On Path to Multimodal Historical Reasoning: HistBench and HistAgent](http://arxiv.org/abs/2505.20246v1)** | 2025-05-26 | 17 pages, 7 figures |
| **[It's High Time: A Survey of Temporal Information Retrieval and Question Answering](http://arxiv.org/abs/2505.20243v1)** | 2025-05-26 |  |
| **[RedAHD: Reduction-Based End-to-End Automatic Heuristic Design with Large Language Models](http://arxiv.org/abs/2505.20242v1)** | 2025-05-26 | Under Review |
| **[DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning](http://arxiv.org/abs/2505.20241v1)** | 2025-05-26 |  |
| **[Seeing is Believing, but How Much? A Comprehensive Analysis of Verbalized Calibration in Vision-Language Models](http://arxiv.org/abs/2505.20236v1)** | 2025-05-26 |  |
| **[FLAME-MoE: A Transparent End-to-End Research Platform for Mixture-of-Experts Language Models](http://arxiv.org/abs/2505.20225v1)** | 2025-05-26 | <details><summary>All c...</summary><p>All code, training logs, and model checkpoints are available at https://github.com/cmu-flame/FLAME-MoE</p></details> |
| **[Chain-of-Thought for Autonomous Driving: A Comprehensive Survey and Future Prospects](http://arxiv.org/abs/2505.20223v1)** | 2025-05-26 | 18 pages, 6 figures |
| **[Fine-grained List-wise Alignment for Generative Medication Recommendation](http://arxiv.org/abs/2505.20218v1)** | 2025-05-26 |  |
| **[Parameter-Efficient Fine-Tuning with Column Space Projection](http://arxiv.org/abs/2505.20211v1)** | 2025-05-26 |  |
| **[How to Improve the Robustness of Closed-Source Models on NLI](http://arxiv.org/abs/2505.20209v1)** | 2025-05-26 |  |
| **[Evaluating Large Language Models for Code Review](http://arxiv.org/abs/2505.20206v1)** | 2025-05-26 |  |
| **[Reasoning Is Not All You Need: Examining LLMs for Multi-Turn Mental Health Conversations](http://arxiv.org/abs/2505.20201v1)** | 2025-05-26 | <details><summary>33 pa...</summary><p>33 pages, 5 figures, 30 tables</p></details> |
| **[Temporal Sampling for Forgotten Reasoning in LLMs](http://arxiv.org/abs/2505.20196v1)** | 2025-05-26 |  |
| **[FunReason: Enhancing Large Language Models' Function Calling via Self-Refinement Multiscale Loss and Automated Data Refinement](http://arxiv.org/abs/2505.20192v1)** | 2025-05-26 |  |

## RAG
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[GTR: Graph-Table-RAG for Cross-Table Question Answering](http://arxiv.org/abs/2504.01346v3)** | 2025-05-26 | 20 pages, 7 figures |
| **[DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through Textual Gradients](http://arxiv.org/abs/2505.19538v1)** | 2025-05-26 | <details><summary>32 pa...</summary><p>32 pages, 5 figures, 5 tables</p></details> |
| **[Removal of Hallucination on Hallucination: Debate-Augmented RAG](http://arxiv.org/abs/2505.18581v1)** | 2025-05-24 | Accepted by ACL 2025 |
| **[Ranking Free RAG: Replacing Re-ranking with Selection in RAG for Sensitive Domains](http://arxiv.org/abs/2505.16014v2)** | 2025-05-23 |  |
| **[MetaGen Blended RAG: Higher Accuracy for Domain-Specific Q&A Without Fine-Tuning](http://arxiv.org/abs/2505.18247v1)** | 2025-05-23 | <details><summary>Prepr...</summary><p>Preprint. Paper Submitted NeurIPS 2025- The Thirty-Ninth Annual Conference on Neural Information Processing Systems</p></details> |
| **[FinRAGBench-V: A Benchmark for Multimodal RAG with Visual Citation in the Financial Domain](http://arxiv.org/abs/2505.17471v1)** | 2025-05-23 |  |
| **[Investigating Language Preference of Multilingual RAG Systems](http://arxiv.org/abs/2502.11175v3)** | 2025-05-23 | ACL 2025 Findings |
| **[VoxRAG: A Step Toward Transcription-Free RAG Systems in Spoken Question Answering](http://arxiv.org/abs/2505.17326v1)** | 2025-05-22 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 Workshop MAGMaR</p></details> |
| **[Personalizing Student-Agent Interactions Using Log-Contextualized Retrieval Augmented Generation (RAG)](http://arxiv.org/abs/2505.17238v1)** | 2025-05-22 | <details><summary>Submi...</summary><p>Submitted to the International Conference on Artificial Intelligence in Education (AIED) Workshop on Epistemics and Decision-Making in AI-Supported Education</p></details> |
| **[FB-RAG: Improving RAG with Forward and Backward Lookup](http://arxiv.org/abs/2505.17206v1)** | 2025-05-22 |  |
| **[Retrieval-Augmented Perception: High-Resolution Image Perception Meets Visual RAG](http://arxiv.org/abs/2503.01222v2)** | 2025-05-22 |  |
| **[PersonaBOT: Bringing Customer Personas to Life with LLMs and RAG](http://arxiv.org/abs/2505.17156v1)** | 2025-05-22 |  |
| **[Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning](http://arxiv.org/abs/2505.14069v2)** | 2025-05-22 |  |
| **[Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the Robustness of RAG Against Misleading Retrievals](http://arxiv.org/abs/2502.16101v2)** | 2025-05-21 |  |
| **[After Retrieval, Before Generation: Enhancing the Trustworthiness of Large Language Models in RAG](http://arxiv.org/abs/2505.17118v1)** | 2025-05-21 | 24 pages, 8 figures |

