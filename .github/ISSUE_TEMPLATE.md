---
title: Latest 15 Papers - April 09, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens](http://arxiv.org/abs/2401.17377v4)** | 2025-04-07 | <details><summary>Publi...</summary><p>Published at COLM 2024, spotlight paper</p></details> |
| **[URECA: Unique Region Caption Anything](http://arxiv.org/abs/2504.05305v1)** | 2025-04-07 | <details><summary>Proje...</summary><p>Project page: https://cvlab-kaist.github.io/URECA Code: https://github.com/cvlab-kaist/URECA</p></details> |
| **[Truthful or Fabricated? Using Causal Attribution to Mitigate Reward Hacking in Explanations](http://arxiv.org/abs/2504.05294v1)** | 2025-04-07 | <details><summary>22 pa...</summary><p>22 pages, 10 figures, 5 tables</p></details> |
| **[PHEONA: An Evaluation Framework for Large Language Model-based Approaches to Computational Phenotyping](http://arxiv.org/abs/2503.19265v2)** | 2025-04-07 | <details><summary>2 fig...</summary><p>2 figures, 5 tables, submitted to 2025 AMIA Annual Symposium</p></details> |
| **[The challenge of uncertainty quantification of large language models in medicine](http://arxiv.org/abs/2504.05278v1)** | 2025-04-07 | 25 pages, 11 figures |
| **[Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented Generation](http://arxiv.org/abs/2504.05276v1)** | 2025-04-07 |  |
| **[Do PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning vs. Memorization in Large Language Models](http://arxiv.org/abs/2504.05262v1)** | 2025-04-07 |  |
| **[Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models](http://arxiv.org/abs/2504.05258v1)** | 2025-04-07 |  |
| **[Explaining Low Perception Model Competency with High-Competency Counterfactuals](http://arxiv.org/abs/2504.05254v1)** | 2025-04-07 |  |
| **[PrefRAG: Preference-Driven Multi-Source Retrieval Augmented Generation](http://arxiv.org/abs/2411.00689v2)** | 2025-04-07 | <details><summary>33 pa...</summary><p>33 pages, 5 figures, 28 tables</p></details> |
| **[LLM-based Automated Grading with Human-in-the-Loop](http://arxiv.org/abs/2504.05239v1)** | 2025-04-07 |  |
| **[DeepNote: Note-Centric Deep Retrieval-Augmented Generation](http://arxiv.org/abs/2410.08821v2)** | 2025-04-07 | <details><summary>28 pa...</summary><p>28 pages, 6 figures, 21 tables</p></details> |
| **[Spider: Any-to-Many Multimodal LLM](http://arxiv.org/abs/2411.09439v2)** | 2025-04-07 |  |
| **[Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG](http://arxiv.org/abs/2504.05220v2)** | 2025-04-08 | 12 pages, 4 figures |
| **[Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood Modeling](http://arxiv.org/abs/2504.05216v1)** | 2025-04-07 | 12 pages, 3 figures |

## RAG
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Real-Time Evaluation Models for RAG: Who Detects Hallucinations Best?](http://arxiv.org/abs/2503.21157v3)** | 2025-04-07 | 11 pages, 8 figures |
| **[Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG](http://arxiv.org/abs/2504.05220v2)** | 2025-04-08 | 12 pages, 4 figures |
| **[Hierarchical Planning for Complex Tasks with Knowledge Graph-RAG and Symbolic Verification](http://arxiv.org/abs/2504.04578v1)** | 2025-04-06 |  |
| **[Driving-RAG: Driving Scenarios Embedding, Search, and RAG Applications](http://arxiv.org/abs/2504.04419v1)** | 2025-04-06 |  |
| **[From Code Generation to Software Testing: AI Copilot with Context-Based RAG](http://arxiv.org/abs/2504.01866v2)** | 2025-04-05 | <details><summary>This ...</summary><p>This work has been accepted for publication in IEEE Software (DOI: 10.1109/MS.2025.3549628)</p></details> |
| **[Retrieving Semantics from the Deep: an RAG Solution for Gesture Synthesis](http://arxiv.org/abs/2412.06786v3)** | 2025-04-04 | <details><summary>CVPR ...</summary><p>CVPR 2025. Project page: https://vcai.mpi-inf.mpg.de/projects/RAG-Gesture/</p></details> |
| **[CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion](http://arxiv.org/abs/2405.16444v3)** | 2025-04-03 |  |
| **[GTR: Graph-Table-RAG for Cross-Table Question Answering](http://arxiv.org/abs/2504.01346v2)** | 2025-04-03 | 20 pages, 7 figures |
| **[Beyond Quacking: Deep Integration of Language Models and RAG into DuckDB](http://arxiv.org/abs/2504.01157v1)** | 2025-04-01 |  |
| **[Self-Routing RAG: Binding Selective Retrieval with Knowledge Verbalization](http://arxiv.org/abs/2504.01018v1)** | 2025-04-01 | Work in Progress |
| **[TOBUGraph: Knowledge Graph-Based Retrieval for Enhanced LLM Performance Beyond RAG](http://arxiv.org/abs/2412.05447v2)** | 2025-04-01 |  |
| **[Contradiction Detection in RAG Systems: Evaluating LLMs as Context Validators for Improved Information Consistency](http://arxiv.org/abs/2504.00180v1)** | 2025-03-31 |  |
| **[A Systematic Evaluation of LLM Strategies for Mental Health Text Analysis: Fine-tuning vs. Prompt Engineering vs. RAG](http://arxiv.org/abs/2503.24307v1)** | 2025-03-31 |  |
| **[A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](http://arxiv.org/abs/2402.07877v3)** | 2025-03-28 |  |
| **[Systematic Knowledge Injection into Large Language Models via Diverse Augmentation for Domain-Specific RAG](http://arxiv.org/abs/2502.08356v3)** | 2025-03-27 | <details><summary>22 pa...</summary><p>22 pages, 14 tables, to be published in NAACL 2025</p></details> |

